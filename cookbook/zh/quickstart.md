---
jupytext:
  formats: md:myst
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.11.5
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

# å¿«é€Ÿå¼€å§‹

æœ¬æ•™ç¨‹æ¼”ç¤ºå¦‚ä½•åœ¨ **AgentScope Runtime** æ¡†æ¶ä¸­æ„å»ºä¸€ä¸ªç®€å•çš„æ™ºèƒ½ä½“å¹¶å°†å…¶éƒ¨ç½²ä¸ºæœåŠ¡ã€‚

## å‰ç½®æ¡ä»¶

### ğŸ”§ å®‰è£…è¦æ±‚

å®‰è£…å¸¦æœ‰åŸºç¡€ä¾èµ–çš„ AgentScope Runtimeï¼š

```bash
pip install agentscope-runtime
```

### ğŸ”‘ APIå¯†é’¥é…ç½®

æ‚¨éœ€è¦ä¸ºæ‰€é€‰çš„å¤§è¯­è¨€æ¨¡å‹æä¾›å•†æä¾›APIå¯†é’¥ã€‚æœ¬ç¤ºä¾‹ä½¿ç”¨DashScopeï¼ˆQwenï¼‰ï¼š

```bash
export DASHSCOPE_API_KEY="your_api_key_here"
```

## åˆ†æ­¥å®ç°

### æ­¥éª¤1ï¼šå¯¼å…¥ä¾èµ–

é¦–å…ˆå¯¼å…¥æ‰€æœ‰å¿…è¦çš„æ¨¡å—ï¼š

```{code-cell}
import os

from agentscope_runtime.engine import AgentApp
from agentscope_runtime.engine.agents.agentscope_agent import AgentScopeAgent
from agentscope_runtime.engine.deployers import LocalDeployManager
from agentscope.model import OpenAIChatModel
from agentscope.agent import ReActAgent


print("âœ… ä¾èµ–å¯¼å…¥æˆåŠŸ")
```

### æ­¥éª¤2ï¼šåˆ›å»ºæ™ºèƒ½ä½“

æˆ‘ä»¬è¿™é‡Œä½¿ç”¨agentscopeä½œä¸ºç¤ºä¾‹ï¼š

```{code-cell}
from agentscope.agent import ReActAgent
from agentscope.model import DashScopeChatModel
from agentscope_runtime.engine.agents.agentscope_agent import AgentScopeAgent

agent = AgentScopeAgent(
    name="Friday",
    model=DashScopeChatModel(
        "qwen-turbo",
        api_key=os.getenv("DASHSCOPE_API_KEY"),
    ),
    agent_config={
        "sys_prompt": "You're a helpful assistant named Friday.",
    },
    agent_builder=ReActAgent,
)

print("âœ… AgentScope agent created successfully")
```

### æ­¥éª¤3ï¼šåˆ›å»ºå¹¶å¯åŠ¨Agent App

ç”¨agentå’Œ `AgentApp` åˆ›å»ºä¸€ä¸ª Agent API æœåŠ¡å™¨ï¼š

```{code-cell}
app = AgentApp(agent=agent, endpoint_path="/process")

app.run(host="0.0.0.0", port=8090)
```

è¿è¡Œåï¼ŒæœåŠ¡å™¨ä¼šå¯åŠ¨å¹¶ç›‘å¬ï¼š`http://localhost:8090/process`

### æ­¥éª¤4ï¼šå‘é€ä¸€ä¸ªè¯·æ±‚

ä½ å¯ä»¥ä½¿ç”¨ `curl` å‘ API å‘é€ JSON è¾“å…¥ï¼š

```bash
curl -N \
  -X POST "http://localhost:8090/process" \
  -H "Content-Type: application/json" \
  -d '{
    "input": [
      {
        "role": "user",
        "content": [
          { "type": "text", "text": "What is the capital of France?" }
        ]
      }
    ]
  }'
```

ä½ å°†ä¼šçœ‹åˆ°ä»¥ **Server-Sent Events (SSE)** æ ¼å¼æµå¼è¾“å‡ºçš„å“åº”ï¼š

```bash
data: {"sequence_number":0,"object":"response","status":"created", ... }
data: {"sequence_number":1,"object":"response","status":"in_progress", ... }
data: {"sequence_number":2,"object":"content","status":"in_progress","text":"The" }
data: {"sequence_number":3,"object":"content","status":"in_progress","text":" capital of France is Paris." }
data: {"sequence_number":4,"object":"message","status":"completed","text":"The capital of France is Paris." }
```

### æ­¥éª¤5: ä½¿ç”¨ Deployer éƒ¨ç½²ä»£ç†

AgentScope Runtime æä¾›äº†ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„éƒ¨ç½²ç³»ç»Ÿï¼Œå¯ä»¥å°†ä½ çš„æ™ºèƒ½ä½“éƒ¨ç½²åˆ°è¿œç¨‹æˆ–æœ¬åœ°å®¹å™¨ä¸­ã€‚è¿™é‡Œæˆ‘ä»¬ä»¥ `LocalDeployManager` ä¸ºä¾‹ï¼š

```{code-cell}
async def main():
    await app.deploy(LocalDeployManager(host="0.0.0.0", port=8091))
```

è¿™æ®µä»£ç ä¼šåœ¨æŒ‡å®šçš„ç«¯å£è¿è¡Œä½ çš„æ™ºèƒ½ä½“API Serverï¼Œä½¿å…¶èƒ½å¤Ÿå“åº”å¤–éƒ¨è¯·æ±‚ã€‚é™¤äº†åŸºæœ¬çš„ HTTP API è®¿é—®å¤–ï¼Œä½ è¿˜å¯ä»¥ä½¿ç”¨ä¸åŒçš„åè®®ä¸æ™ºèƒ½ä½“è¿›è¡Œäº¤äº’ï¼Œä¾‹å¦‚ï¼šA2Aã€Response APIã€Agent APIç­‰ã€‚è¯¦æƒ…è¯·å‚è€ƒ {doc}`protocol`ã€‚

ä¾‹å¦‚ç”¨æˆ·å¯ä»¥é€šè¿‡OpenAI SDK æ¥è¯·æ±‚è¿™ä¸ªéƒ¨ç½²ã€‚

```python
from openai import OpenAI

client = OpenAI(base_url="http://0.0.0.0:8091/compatible-mode/v1")

response = client.responses.create(
  model="any_name",
  input="æ­å·å¤©æ°”å¦‚ä½•ï¼Ÿ"
)

print(response)
```